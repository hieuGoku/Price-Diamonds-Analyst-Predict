{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Thu thập đường dẫn của dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collect_Href_of_Diamonds(shape):\n",
    "    url = \"https://www.allurez.com/loose-diamonds/?filterVal=yes&shape={}\".format(shape)\n",
    "\n",
    "    # Khởi tạo trình duyệt Chrome\n",
    "    ser = Service(\"C:/Program Files (x86)/chromedriver.exe\")\n",
    "    driver = webdriver.Chrome(service = ser)\n",
    "\n",
    "    # Mở trang web\n",
    "    driver.get(url)\n",
    "    driver.fullscreen_window()\n",
    "\n",
    "    # Thay đổi view\n",
    "    time.sleep(5)\n",
    "    link = driver.find_element(By.ID, 'grid_view')\n",
    "    link.click()\n",
    "\n",
    "    link_href = set()\n",
    "\n",
    "    # Nhấn Seemore\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            # Find the link by its attributes using the By.XPATH locator\n",
    "            see_more_button = driver.find_element(By.XPATH, '//a[@class=\"btn_new2\" and text()=\"See More...\"]')\n",
    "            # Click the link\n",
    "            see_more_button.click()\n",
    "            # driver.implicitly_wait(60)\n",
    "            time.sleep(5)\n",
    "            # Find data\n",
    "            divs = driver.find_elements(By.CLASS_NAME, \"name\")\n",
    "\n",
    "            # Find data\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            # Find the <ul> tag with class \"dmd_grid_view\"\n",
    "            ul_tag = soup.find(\"ul\", {\"class\": \"dmd_grid_view\"})\n",
    "            if(ul_tag != None):\n",
    "                # Extract all the <li> tags inside the <ul> tag\n",
    "                li_tags = ul_tag.find_all(\"li\")\n",
    "                for li in li_tags:\n",
    "                    d = li.find(\"div\", {\"class\" : \"name\"})\n",
    "                    if(d != None):\n",
    "                        a = d.find(\"a\")\n",
    "                        link_href.add(a.get(\"href\"))\n",
    "            \n",
    "            if(len(link_href) > 1500):\n",
    "                return link_href\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "        except StaleElementReferenceException:\n",
    "            break\n",
    "        except ElementNotInteractableException:\n",
    "            break\n",
    "    # Find data\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    # Find the <ul> tag with class \"dmd_grid_view\"\n",
    "    ul_tag = soup.find(\"ul\", {\"class\": \"dmd_grid_view\"})\n",
    "    if(ul_tag != None):\n",
    "        # Extract all the <li> tags inside the <ul> tag\n",
    "        li_tags = ul_tag.find_all(\"li\")\n",
    "        for li in li_tags:\n",
    "            d = li.find(\"div\", {\"class\" : \"name\"})\n",
    "            if(d != None):\n",
    "                a = d.find(\"a\")\n",
    "                link_href.add(a.get(\"href\"))\n",
    "\n",
    "    driver.quit()\n",
    "    return link_href"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thu thập đường dẫn của từng Shape và đưa vào thư mục Link_Diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [\"Round\", \"Princess\", \"Cushion\", \"Emerald\", \"Asscher\", \"Marquise\", \"Oval\", \"Radiant\", \"Pear\", \"Heart\"]\n",
    "\n",
    "for shape in shapes:\n",
    "    path = \"./Link_Diamonds/\" + shape + \".txt\"\n",
    "    with open(path, \"w\") as f:\n",
    "        links = Collect_Href_of_Diamonds(shape = shape)\n",
    "        for link in links:\n",
    "            f.write(link + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gộp các đường dẫn vào 2 file link_big.txt và link_small.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [\"Round\", \"Princess\", \"Cushion\", \"Emerald\", \"Asscher\", \"Marquise\", \"Oval\", \"Radiant\", \"Pear\", \"Heart\"]\n",
    "\n",
    "with open(\"link_big.txt\", \"w\") as file:\n",
    "    for shape in shapes:\n",
    "        path = \"./Link_Diamonds/\" + shape + \".txt\"\n",
    "        with open(path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [\"Round\", \"Princess\", \"Cushion\", \"Emerald\", \"Asscher\", \"Marquise\", \"Oval\", \"Radiant\", \"Pear\", \"Heart\"]\n",
    "\n",
    "with open(\"link_small.txt\", \"w\") as file:\n",
    "    for shape in shapes:\n",
    "        path = \"./Link_Diamonds/\" + shape + \".txt\"\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            np.random.shuffle(lines)\n",
    "            for line in lines[:110]:\n",
    "                file.write(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Thu thập tất cả các dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collect_Raw_Data(url):\n",
    "    result = requests.get(url)\n",
    "    html = BeautifulSoup(result.text, \"html.parser\")\n",
    "    record = \"\"\n",
    "    tables = html.find_all(\"table\", {\"class\" : \"dtlnt_infotable\"})\n",
    "    for table in tables:\n",
    "        infors = table.find_all(\"tr\")\n",
    "        for infor in infors:\n",
    "            tds = infor.find_all(\"td\")\n",
    "            if len(tds) == 2:\n",
    "                key = \"\"\n",
    "                if tds[0].find(\"a\") == None:\n",
    "                    key = tds[0].find(\"span\").text\n",
    "                else:\n",
    "                    key = tds[0].find(\"a\").text\n",
    "                val = tds[1].text\n",
    "                record += key.strip() + \":\" + val.strip() + \",\"\n",
    "    price = html.find(\"span\", {\"class\" : \"listprice dlp\"})\n",
    "    if price != None:\n",
    "        p = price.text.replace(\"$\", \"\").replace(\",\", \"\")\n",
    "        record += \"Price:\" + p\n",
    "\n",
    "    return record"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thu thập dữ liệu từ file link_big.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_big = []\n",
    "with open(\"link_big.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        data = Collect_Raw_Data(line.rstrip(\"\\n\"))\n",
    "        raw_data_big.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Raw_Data/data_big.txt\", \"w\") as f:\n",
    "    for raw in raw_data_big:\n",
    "        f.write(raw + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ==> Thu được tất cả dữ liệu lấy được  trong file data_big.txt trong thư mục Raw_Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thu thập dữ liệu từ file link_small.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_small = []\n",
    "with open(\"link_small.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        data = Collect_Raw_Data(line.rstrip(\"\\n\"))\n",
    "        raw_data_small.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Raw_Data/data_small.txt\", \"w\") as f:\n",
    "    for raw in raw_data_small:\n",
    "        f.write(raw + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ==> Thu được tất cả dữ liệu lấy được  trong file data_small.txt trong thư mục Raw_Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chuyển đổi dữ liệu thành file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert_line_to_CSV(line, columns):\n",
    "    features = line.rstrip(\"\\n\").split(\",\")\n",
    "    # lấy đặc trưng và giá trị\n",
    "    keys = []\n",
    "    vals = []\n",
    "    for feature in features:\n",
    "        keys.append(feature.split(\":\")[0])\n",
    "        vals.append(feature.split(\":\")[1])\n",
    "    # Ghi lên file\n",
    "    record = \"\"\n",
    "    for column in columns:\n",
    "        if(column in keys):\n",
    "            index = keys.index(column)\n",
    "            if(column == \"Price\"):\n",
    "                vals[index] = vals[index].replace(\".\", \"\")\n",
    "            record += vals[index] + \",\"\n",
    "        else:\n",
    "            record += \",\"\n",
    "    return record[:-1] + \"\\n\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuyển đổi file data_big.txt trong Raw_Data thành file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Style Number', 'Shape', 'Carat Weight', 'Color', 'Clarity', 'Graded By', 'Cut Grade', 'Fluorescence', 'Culet', 'Depth', 'Table', 'Girdle', 'Polish', 'Symmetry', 'Measurements', 'Price']\n",
    "\n",
    "with open(\"./Raw_Data/data_big.csv\", \"w\") as f:\n",
    "    cols = \"\"\n",
    "    for column in columns:\n",
    "        cols += column + \",\"\n",
    "    f.write(cols[:-1] + \"\\n\")\n",
    "    with open(\"./Raw_Data/data_big.txt\", \"r\") as datas:\n",
    "        for line in datas.readlines():\n",
    "            record = Convert_line_to_CSV(line, columns)\n",
    "            f.write(record)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuyển đổi file data_small.txt trong Raw_Data thành file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Style Number', 'Shape', 'Carat Weight', 'Color', 'Clarity', 'Graded By', 'Cut Grade', 'Fluorescence', 'Culet', 'Depth', 'Table', 'Girdle', 'Polish', 'Symmetry', 'Measurements', 'Price']\n",
    "\n",
    "with open(\"./Raw_Data/data_small.csv\", \"w\") as f:\n",
    "    cols = \"\"\n",
    "    for column in columns:\n",
    "        cols += column + \",\"\n",
    "    f.write(cols[:-1] + \"\\n\")\n",
    "    with open(\"./Raw_Data/data_small.txt\", \"r\") as datas:\n",
    "        for line in datas.readlines():\n",
    "            record = Convert_line_to_CSV(line, columns)\n",
    "            f.write(record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
